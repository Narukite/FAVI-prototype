{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict_using_cloud.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhUZLT8C0elr"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohoPiVV_HZzv"
      },
      "source": [
        "pip install --upgrade google-api-python-client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckgb2AKs0JFT"
      },
      "source": [
        "from google.cloud import storage\n",
        "from google.api_core.client_options import ClientOptions\n",
        "import googleapiclient.discovery\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpqns4at0YpN"
      },
      "source": [
        "def predict_json(project, region, model, instances, version=None):\n",
        "    prefix = \"{}-ml\".format(region) if region else \"ml\"\n",
        "    api_endpoint = \"https://{}.googleapis.com\".format(prefix)\n",
        "    client_options = ClientOptions(api_endpoint=api_endpoint)\n",
        "    service = googleapiclient.discovery.build('ml', \n",
        "                                              'v1',\n",
        "                                              client_options=client_options\n",
        "                                              )\n",
        "    name = 'projects/{}/models/{}'.format(project, model)\n",
        "\n",
        "    if version is not None:\n",
        "        name += '/versions/{}'.format(version)\n",
        "\n",
        "    response = service.projects().predict(\n",
        "        name=name,\n",
        "        body={'instances': instances}\n",
        "    ).execute()\n",
        "\n",
        "    if 'error' in response:\n",
        "        raise RuntimeError(response['error'])\n",
        "\n",
        "    return response['predictions']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi7y_76O0xY6"
      },
      "source": [
        "  _mapping = [\"sembilan\", \n",
        "              \"tiga\", \n",
        "              \"tujuh\", \n",
        "              \"satu\", \n",
        "              \"delapan\", \n",
        "              \"enam\",\n",
        "              \"tambah\", \n",
        "              \"transfer\", \n",
        "              \"lima\", \n",
        "              \"empat\", \n",
        "              \"nol\", \n",
        "              \"dua\"\n",
        "             ]\n",
        "  SAMPLES_TO_CONSIDER = 16000\n",
        "\n",
        "  def preprocess(file_path, num_mfcc=13, n_fft=2048, hop_length=512):\n",
        "\n",
        "    #load audio file\n",
        "    signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "    if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "      #ensure consistency of the length of the signal\n",
        "      signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "  \n",
        "      #extract MFCCs\n",
        "      MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                   hop_length=hop_length)\n",
        "    return MFCCs.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnN_uhPY1ng7"
      },
      "source": [
        "audio_file = '000A_tambah.wav'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhE9uGq11PJO"
      },
      "source": [
        "MFCCs = preprocess(audio_file)\n",
        "MFCCs = MFCCs[np.newaxis, ..., np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GghbYICh7ynd"
      },
      "source": [
        "project = 'the-late-night-studio'\n",
        "region = 'asia-southeast1'\n",
        "model = 'favi_speech_model'\n",
        "version = 'v02'\n",
        "instances = MFCCs.tolist()\n",
        "test_predictions = predict_json(project, region, model, instances, version)\n",
        "idx = np.argmax(test_predictions[0])\n",
        "print(idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWRKLl6MIxuy"
      },
      "source": [
        "prediction = _mapping[idx]\n",
        "print('favi prediction: {}'.format(prediction))\n",
        "response_json = {\"Prediction\": prediction}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nclQ1kxlcTo6"
      },
      "source": [
        "pip freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}